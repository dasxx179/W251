Tensorflow v2 Questions
1. What's the structure of the network that's being used for classification?
Answer: It is single-layer and has 128 input nodes followed by a dropout layer that helps with overfitting.  It also has a dense prediction layer of 10 nodes where each node is for each number 0-9.  
2. How good is it?
Answer:  It is good.  My accuracy is .9764.
3. Based on what you learned in homework 4, can you beat it?
Answer:  I was able to improve the network by adding another hidden layer with 64 nodes and a dropout layer.  The accuracy is now .978, so yes I was able to improve it.  
4. What is your batch size?
Answer: I tried a batch size of 4
5. Can you improve model accuracy?
I got model accuracy of 1.0 with layers frozen.  
With layers unfrozen and still having 2 epochs I got:
Train for 918.0 steps
Epoch 1/2
918/918 [==============================] - 329s 359ms/step - loss: 1.1929 - acc: 0.5000
Epoch 2/2
918/918 [==============================] - 324s 353ms/step - loss: 0.9029 - acc: 1.0000

Tensorflow v1 Questions
1. What is TensorFlow? Which company is the leading contributor to TensorFlow?
Answer: TensorFlow is an open source artificial intelligence library, using data flow graphs to build models.  Google is the leading contributor to TensorFlow.  
2. What is TensorRT? How is it different from TensorFlow?
Answer:  TensorRT is an SDK by NVIDIA that works in conjunction with TensorFlow.  It optimizes models and can reduce training time while still improving accuracy and performance for models generated by TensorFlow.  
3. What is ImageNet? How many images does it contain? How many classes?
Answer:  ImageNet is an image database based on WordNet.  WordNet involves grouping together a group of words to describe a concept, and these groupings are called synsets.  ImageNet provides about 1000 images per synset, and there are over 100,000 synsets, implying over 100,000,000 images.  
ImageNet statistics as of April 30, 2010:
Total number of non-empty synsets: 21841
Total number of images: 14,197,122
Number of images with bounding box annotations: 1,034,908
Number of synsets with SIFT features: 1000
Number of images with SIFT features: 1.2 million
4. Please research and explain the differences between MobileNet and GoogleNet (Inception) architectures.
Answer:  MobileNet is an architecture which is more suitable for mobile and embedded based vision applications where there is lack of compute power. This architecture was proposed by Google.  GoogLeNet is a pretrained convolutional neural network that is 22 layers deep.  You can train on ImageNet or Places365 data sets, and the network trained on ImageNet classifies images into 1000 object categories.  
5. In your own words, what is a bottleneck?
Answer:  It is the layer that is right before the last output layer.  
6. How is a bottleneck different from the concept of layer freezing?
Answer:  In ML, a bottleneck is the last pre processing phase before the actual training begins.  Layer freezing means layer weights of a trained model are not changed when used later on.  
7. In the TF1 lab, you trained the last layer (all the previous layers retain their already-trained state). Explain how the lab used the previous layers (where did they come from? how were they used in the process?)
Answer: The weights of the previous layers are from a different process that are basically frozen.  The new dataset was created through back propagation from the final layers weights.  This is an example of fine tuning the model.  
8. How does a low --learning_rate (step 7 of TF1) value (like 0.005) affect the precision? How much longer does training take?
Answer:  A lower learning rate helps the model improve its accuracy.  Training time is pretty similar but slightly longer. 
9. How about a --learning_rate (step 7 of TF1) of 1.0? Is the precision still good enough to produce a usable graph?
Answer:  Precision decreases heavily with a higher learning rate.  The accuracy even seems to get worse the more the model is trained.  
10. For step 8, you can use any images you like. Pictures of food, people, or animals work well. You can even use ImageNet images. How accurate was your model? Were you able to train it using a few images, or did you need a lot?
Answer:  I trained the model with a large amount of images.  The model reached a high degree of accuracy of around .95.
11. Run the TF1 script on the CPU (see instructions above) How does the training time compare to the default network training (section 4)? Why?
Answer:  container is faster because of GPU compared to slower training time with CPU.  
12. Try the training again, but this time do export ARCHITECTURE="inception_v3" Are CPU and GPU training times different?
Answer: cpu took about 2.75 minutes while gpu was done in about 1.5 minutes. 
13. Given the hints under the notes section, if we trained Inception_v3, what do we need to pass to replace ??? below to the label_image script? Can we also glean the answer from examining TensorBoard?
python -m scripts.label_image --input_layer=Mul --input_height=299 --input_width=299  --graph=tf_files/retrained_graph.pb --image=tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg

